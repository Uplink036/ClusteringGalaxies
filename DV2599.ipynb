{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "- [Table of contents](#table-of-contents)\n",
    "- [Imports](#imports)\n",
    "  - [Flags](#flags)\n",
    "- [Preprocessing](#preprocessing)\n",
    "  - [Functions](#functions-preprocessing)\n",
    "  - [Primary](#primary-preprocessing)\n",
    "- [Clustering](#clustering)\n",
    "  - [Functions](#functions-clustering)\n",
    "  - [DBSCAN](#dbscan)\n",
    "  - [PCA](#pca)\n",
    "  - [Agglomerative Clustering](#agglomerative-clustering)\n",
    "  - [SOM](#som)\n",
    "- [Testing](#testing)\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "zAz2JxsbJkBf8Sg3SnuHtf",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import skimage as ski\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from minisom import MiniSom\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.cluster import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering\n",
    "from skimage.io import ImageCollection\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flags\n",
    "[To the top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAGS \n",
    "FILTER_IMAGES = True\n",
    "PREPROCESS_IMAGES = True\n",
    "VERBOSE = True\n",
    "VERBOSE_FUNCTIONS = False\n",
    "FOLDERS_OF_INTEREST = [\"images_training_subfolder31\", \"images_training_subfolder3\"]\n",
    "LOCATION_OF_PREPPED_IMAGES = \"prepped_images/\"\n",
    "FOLDER_OF_PREPPED_IMAGES =  [ LOCATION_OF_PREPPED_IMAGES + folder for folder in FOLDERS_OF_INTEREST]\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and data transformation\n",
    "### Functions Preprocessing\n",
    "[To the top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "D4zaCkGRce0eKEDS0C7bHc",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class Galaxy:\n",
    "    def __init__(self, x, y, sigma):\n",
    "        self._x = x\n",
    "        self._y = y\n",
    "        self._sigma = sigma\n",
    "    \n",
    "    @property\n",
    "    def center(self):\n",
    "        return [self._x, self._y]\n",
    "    \n",
    "    @property\n",
    "    def radius(self):\n",
    "        factor = np.sqrt(2)\n",
    "        return factor*self._sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(galaxyID, test_true=False, train_true=False):\n",
    "    if galaxyID is None:\n",
    "        return None\n",
    "    if isinstance(galaxyID, int):\n",
    "        galaxyID = str(galaxyID)\n",
    "    # Get the current working directory\n",
    "    current_dir = os.getcwd()\n",
    "    # Search through the subfolders for the image with the same ID\n",
    "    search_dir = current_dir\n",
    "    for root, dirs, files in os.walk(search_dir):\n",
    "        for file in files:\n",
    "            if file.startswith(galaxyID) and file.endswith('.jpg'):\n",
    "                return os.path.join(root, file)\n",
    "\n",
    "    # If the image is not found, return None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cropp_image(image, center_x, center_y, radius):\n",
    "    return image[int(center_x-radius):int(center_x+radius), int(center_y-radius):int(center_y+radius)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def overlap(image, galaxy1:Galaxy, galaxy2:Galaxy, verbose=False):\n",
    "    top_galaxy, bottom_galaxy = (galaxy1, galaxy2) if galaxy1.center[1] > galaxy2.center[1] else (galaxy2, galaxy1) \n",
    "    # top_galaxy will be the one most to the bottom of the pictures\n",
    "    # This is because of the pixel coordinates, where the y-axis is inverted\n",
    "    \n",
    "    D = np.sqrt((top_galaxy.center[0]-bottom_galaxy.center[0])**2 + (top_galaxy.center[1]-bottom_galaxy.center[1])**2)\n",
    "    alpha = np.arcsin((top_galaxy.center[0]-bottom_galaxy.center[0])/D)\n",
    "\n",
    "    if top_galaxy.center[0] < bottom_galaxy.center[0]:\n",
    "        alpha = np.pi/2+alpha\n",
    "    else:\n",
    "        alpha = np.pi/2+alpha\n",
    "\n",
    "    closest_point = [int(top_galaxy.center[0] + top_galaxy.radius*np.cos(alpha)), int(top_galaxy.center[1] - top_galaxy.radius*np.sin(alpha))]\n",
    "    if verbose:\n",
    "        print(f\"Closest point: {closest_point}\")\n",
    "        print(f\"Distance: {D}\")\n",
    "        print(f\"Alpha: {alpha/np.pi*180} degrees\")\n",
    "        print(f\"Top Galaxy center: {top_galaxy.center}\")\n",
    "        print(f\"Bottom Galaxy center: {bottom_galaxy.center}\")\n",
    "\n",
    "        #plot the two galaxies\n",
    "        ski.io.imshow(image)\n",
    "        plt.plot(top_galaxy.center[0], top_galaxy.center[1], 'go')\n",
    "        plt.plot(bottom_galaxy.center[0], bottom_galaxy.center[1], 'go')\n",
    "        #plot the closest point onto the image\n",
    "   \n",
    "        plt.plot(closest_point[0], closest_point[1], 'ro')\n",
    "        \n",
    "        plt.plot([top_galaxy.center[0], bottom_galaxy.center[0]], [top_galaxy.center[1], bottom_galaxy.center[1]], 'r-')\n",
    "        plt.show()\n",
    "    if np.sqrt((closest_point[0]-bottom_galaxy.center[0])**2 + (closest_point[1]-bottom_galaxy.center[1])**2) < bottom_galaxy.radius:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_galaxy(image, window, verbose=False):\n",
    "    blobs = ski.feature.blob_doh(image,\n",
    "                                threshold=0.004, \n",
    "                                max_sigma = 100,\n",
    "                                overlap=1)\n",
    "    if verbose:\n",
    "        print(blobs)\n",
    "    image_center = [image.shape[0]//2, image.shape[1]//2]\n",
    "    found_galaxy = None\n",
    "    largest_sigma = 0\n",
    "    blobs_in_window = []\n",
    "    for b in blobs:\n",
    "        if all(abs(b[i] - image_center[i]) < window for i in range(2)) and b[2] > largest_sigma:\n",
    "            blobs_in_window.append(b)\n",
    "            largest_sigma = b[2]\n",
    "            found_galaxy = b\n",
    "\n",
    "    if found_galaxy is None:\n",
    "        return None\n",
    "        \n",
    "    found_galaxy = Galaxy(found_galaxy[1], found_galaxy[0], found_galaxy[2])\n",
    "\n",
    "    for b in blobs:\n",
    "        blob = Galaxy(b[1], b[0], b[2])\n",
    "        if blob.center != found_galaxy.center:\n",
    "            # Check if they overlap\n",
    "            if overlap(image, found_galaxy, blob, verbose=verbose):\n",
    "                if verbose:\n",
    "                    print(f\"There is overlap between {found_galaxy.center} and {blob.center}\")\n",
    "                return False\n",
    "    return found_galaxy\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_black_stripe(image, verbose=False):\n",
    "    # If there is at least 10 dark pixels in a row of any angle that are surrounded by light pixels, then there is a black stripe\n",
    "    # image is cropped and gray scaled\n",
    "\n",
    "    dark_pixel_threshold = 0.1\n",
    "    dark_pixel_count_threshold = 15\n",
    "    bright_pixel_threshold = 0.2\n",
    "\n",
    "    dark_pixels = []\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            if image[i][j] < dark_pixel_threshold:\n",
    "                dark_pixels.append([i,j])\n",
    "    \n",
    "    bright_pixels = []\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            if image[i][j] > bright_pixel_threshold:\n",
    "                bright_pixels.append([i,j])\n",
    "\n",
    "\n",
    "    suspicious_pixels = []\n",
    "    # Look at a window around each dark pixel\n",
    "    # If the mean of the pixels in the window is above the bright pixel threshold, add it to the list of suspicious pixels\n",
    "    for pixel in dark_pixels:\n",
    "        window = 5\n",
    "        window_pixels = []\n",
    "        for i in range(pixel[0]-window, pixel[0]+window):\n",
    "            for j in range(pixel[1]-window, pixel[1]+window):\n",
    "                if i >= 0 and i < image.shape[0] and j >= 0 and j < image.shape[1]:\n",
    "                    window_pixels.append(image[i][j])\n",
    "        if np.mean(window_pixels) > bright_pixel_threshold:\n",
    "            suspicious_pixels.append(pixel)\n",
    "\n",
    "    #Plot the dark pixels onto the image\n",
    "    if verbose:\n",
    "        ski.io.imshow(image)\n",
    "        \n",
    "        for pixel in bright_pixels:\n",
    "            plt.plot(pixel[1], pixel[0], 'bo')\n",
    "        for pixel in dark_pixels:\n",
    "            plt.plot(pixel[1], pixel[0], 'ro')\n",
    "        for pixel in suspicious_pixels:\n",
    "            plt.plot(pixel[1], pixel[0], 'go')\n",
    "        plt.show()\n",
    "\n",
    "    # How many suspicious pixels are there?\n",
    "    if len(suspicious_pixels) > dark_pixel_count_threshold:\n",
    "        # Do linear regression on the suspicious pixels\n",
    "        # If the R^2 value is high, then there is a black stripe\n",
    "\n",
    "        # Get the x and y values of the suspicious pixels\n",
    "        x = []\n",
    "        y = []\n",
    "        for pixel in suspicious_pixels:\n",
    "            x.append(pixel[0])\n",
    "            y.append(pixel[1])\n",
    "        # Do linear regression with numpy\n",
    "        slope, intercept = np.polyfit(x, y, 1)\n",
    "        #Plot the line\n",
    "        if verbose:\n",
    "            plt.plot(x, y, 'ro')\n",
    "            plt.plot(x, [slope*x[i] + intercept for i in range(len(x))], 'b')\n",
    "            plt.show()\n",
    "        # Get the R^2 value\n",
    "        r_squared = np.corrcoef(x, y)[0,1]**2\n",
    "        # If the R^2 value is high, then there is a black stripe\n",
    "        print(f\"R^2 = {r_squared}\")\n",
    "        if r_squared > 0.3:\n",
    "            print(\"Black Stripe found\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Black Stripe was not found\")\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "HMqMpWTrd5SCXo6fkonbyF",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def get_covariance_matrix(image, x_size, y_size):\n",
    "    coord_rows = []\n",
    "    coord_columns = []\n",
    "    for index_row in range(0, x_size):\n",
    "        for index_column in range(0, y_size):\n",
    "            if image[index_row][index_column] == 1:\n",
    "                coord_rows.append(index_row)\n",
    "                coord_columns.append(index_column)\n",
    "    cov_matrix = np.cov(coord_rows, y=coord_columns)\n",
    "    return cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "8jUeutfRNQNbv2iuFFi93m",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_rotation_on_image(image, verbose=False):\n",
    "    binary_image = ski.util.img_as_bool(image)\n",
    "    if verbose:\n",
    "        ski.io.imshow(binary_image)\n",
    "        pass\n",
    "    \n",
    "    cov_matrix = get_covariance_matrix(binary_image, len(binary_image), len(binary_image[0]))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"cov_matrix[0] = \\t[{cov_matrix[0][0]}, {cov_matrix[0][1]}]\")\n",
    "        print(f\"cov_matrix[1] = \\t[{cov_matrix[1][0]}, {cov_matrix[1][1]}]\")\n",
    "    result = np.linalg.eigh(cov_matrix)\n",
    "    eigenvalues = result[0]\n",
    "    eigenvectors = result[1]\n",
    "\n",
    "    \n",
    "    max_eigen_index, = np.where(np.isclose(eigenvalues, max(eigenvalues)))[0]\n",
    "    if verbose:\n",
    "        print(f\"Eigenvalues     = \\t[{eigenvalues[0]}, {eigenvalues[1]}]\")\n",
    "        print(f\"eigenvectors[0] = \\t[{eigenvectors[0][0]}, {eigenvectors[0][1]}]\")\n",
    "        print(f\"eigenvectors[1] = \\t[{eigenvectors[1][0]}, {eigenvectors[1][1]}]\")\n",
    "        print(eigenvectors[max_eigen_index][0])\n",
    "        print(eigenvectors[(max_eigen_index+1)%2][1])\n",
    "    rotations_in_radians = np.arccos((eigenvectors[max_eigen_index][0]+eigenvectors[(max_eigen_index+1)%2][1]) / 2)\n",
    "    rotation_in_degrees = np.rad2deg(rotations_in_radians)\n",
    "    if rotation_in_degrees > 90:\n",
    "        rotation_in_degrees = 180 - rotation_in_degrees\n",
    "\n",
    "\n",
    "    if (eigenvectors[max_eigen_index][0] * eigenvectors[max_eigen_index][1]) > 0:\n",
    "        rotation_in_degrees = -rotation_in_degrees\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Rotating images with the deg\", rotation_in_degrees)\n",
    "        # ski.io.imshow(ski.transform.rotate(image, rotation_in_degrees))\n",
    "\n",
    "    return rotation_in_degrees+90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_image(img, verbose=False):\n",
    "    \"\"\"\n",
    "    Very simple function that is only supposed to use already existing functions with minimal interaction to handle a picture.\n",
    "    \n",
    "    It should return true if it's filtered out and false if it's not.\n",
    "    \"\"\"\n",
    "    gray_img = ski.color.rgb2gray(img)\n",
    "    galaxy = find_galaxy(gray_img, window=50, verbose=verbose) \n",
    "    if galaxy is None or galaxy is False:\n",
    "        return True\n",
    "    \n",
    "    cropped_img = cropp_image(gray_img, galaxy.center[0], galaxy.center[1], galaxy.radius)\n",
    "    cropped_exposed_img = ski.exposure.rescale_intensity(cropped_img)\n",
    "    return_value = check_for_black_stripe(cropped_exposed_img, verbose=verbose) ## Not implemented\n",
    "    if return_value is True:\n",
    "        return True\n",
    "        \n",
    "    return galaxy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(img, galaxy, verbose=False):\n",
    "    \"\"\"\n",
    "    Function that should handle the image and return a cropped and rotated image.\n",
    "    \"\"\"  \n",
    "    gray_img = ski.color.rgb2gray(img)  \n",
    "    cropped_img = cropp_image(gray_img, galaxy.center[0], galaxy.center[1], galaxy.radius)\n",
    "    cropped_exposed_img = ski.exposure.rescale_intensity(cropped_img)\n",
    "    angle = get_rotation_on_image(cropped_exposed_img, verbose=verbose)\n",
    "    rotated_image = ski.transform.rotate(gray_img, angle)\n",
    "    cropped_rotated_img = cropp_image(rotated_image, galaxy.center[0], galaxy.center[1], galaxy.radius)\n",
    "    resized_cropped_rotated_image = ski.transform.resize(cropped_rotated_img, (128, 128))\n",
    "    resized_cropped_rotated_image = ski.exposure.rescale_intensity(resized_cropped_rotated_image)\n",
    "    return resized_cropped_rotated_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folders, verbose=False, conserve_memory=False):\n",
    "    for folder in folders:\n",
    "        if not os.path.isdir(f\"./{folder}\"):\n",
    "            raise ValueError(f\"Folder {folder} does not exist\")\n",
    "\n",
    "        if not os.path.isdir(f\"./{LOCATION_OF_PREPPED_IMAGES}/{folder}\"):\n",
    "            os.mkdir(f\"./{LOCATION_OF_PREPPED_IMAGES}/{folder}\")\n",
    "            if verbose:\n",
    "                print(f\"Created folder {LOCATION_OF_PREPPED_IMAGES}/{folder}\")\n",
    "\n",
    "    images = ImageCollection(folder + \"/*.jpg\", conserve_memory=conserve_memory)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary-Preprocessing\n",
    "- [To the top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_of_images = 0\n",
    "number_of_filtered_images = 0\n",
    "\n",
    "for folder in FOLDERS_OF_INTEREST:\n",
    "    image_collection = load_images_from_folder([folder], verbose=VERBOSE_FUNCTIONS, conserve_memory=True)\n",
    "    \n",
    "    for index, image in enumerate(image_collection):\n",
    "        name = image_collection.files[index].split(\"/\")[-1].split(\".\")[0]\n",
    "        if VERBOSE:\n",
    "            print(f\"Image[{index}]\")\n",
    "\n",
    "        if FILTER_IMAGES:\n",
    "            return_value = filter_image(image, verbose=VERBOSE_FUNCTIONS) \n",
    "            if return_value is True:\n",
    "                if VERBOSE:\n",
    "                    print(f\"Image[{name}] was filtered out\")\n",
    "                number_of_filtered_images += 1\n",
    "                continue \n",
    "            galaxy = return_value\n",
    "            if VERBOSE:\n",
    "                print(\"Image passed filter\")\n",
    "        else:\n",
    "            galaxy = find_galaxy(ski.color.rgb2gray(image), window=50, verbose=VERBOSE_FUNCTIONS) \n",
    "            if galaxy is None or galaxy is False:\n",
    "                continue\n",
    "        \n",
    "            \n",
    "        if PREPROCESS_IMAGES:\n",
    "            preprocessed_image = preprocess_image(image, galaxy, VERBOSE_FUNCTIONS)\n",
    "            # Send image to prepped_images folder\n",
    "            # Make it a tiff file§\n",
    "            image = ski.img_as_ubyte(preprocessed_image)\n",
    "            # If the folder does not exist, create it\n",
    "            ski.io.imsave(f\"./prepped_images/{folder}/{name}.tiff\", image)\n",
    "            if VERBOSE:\n",
    "                print(\"Image was preprocessed\")\n",
    "                ski.io.imshow(preprocessed_image)\n",
    "        number_of_images += 1\n",
    "if VERBOSE:\n",
    "    print(\"Done\")\n",
    "    print(f\"Number of images: {number_of_images}\")\n",
    "    print(f\"Number of filtered images: {number_of_filtered_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "Now, we have a dataset of images with one galaxy in the middle. Next step is to work with the data and cluster it.\n",
    "\n",
    "### Functions Clustering\n",
    "\n",
    "[To the top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(image):\n",
    "    flattened_image = []\n",
    "    for row in image:\n",
    "        for pixel in row:\n",
    "            flattened_image.append(pixel)\n",
    "    # Scale to between 0 and 10 from 0 and 255\n",
    "    flattened_image = np.array(flattened_image)\n",
    "    flattened_image = flattened_image/255\n",
    "    return flattened_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(images, labels, n_clusters_):\n",
    "    # Get the indices of the images in each cluster\n",
    "\n",
    "    \n",
    "\n",
    "    indices = []\n",
    "    for i in range(n_clusters_):\n",
    "        indices.append([])\n",
    "    for i in range(len(labels)):\n",
    "        indices[labels[i]].append(i)\n",
    "\n",
    "    # Plot the images\n",
    "    for i in range(n_clusters_):\n",
    "        image_amount = 10 if len(indices[i]) > 10 else len(indices[i])\n",
    "        plt.figure(figsize=(image_amount, 1))\n",
    "        #Add the title\n",
    "        plt.suptitle(f\"Cluster {i}\")\n",
    "        cluster_indices = indices[i]\n",
    "        random_images_index = np.random.choice(cluster_indices, image_amount, replace=False)\n",
    "        for j in range(image_amount ):\n",
    "            plt.subplot(1, image_amount, j+1)\n",
    "            plt.axis('off')\n",
    "            \n",
    "\n",
    "            # Get a set of image indexs that are not the same \n",
    "\n",
    "            plt.imshow(images[random_images_index[j]].reshape(128, 128), cmap=cm.gray)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_real_clusters(imageIDs, labels, n_clusters_):\n",
    "    # Get the indices of the images in each cluster\n",
    "\n",
    "    image_amount = 10\n",
    "\n",
    "    indices = []\n",
    "    for i in range(n_clusters_):\n",
    "        indices.append([])\n",
    "    for i in range(len(labels)):\n",
    "        indices[labels[i]].append(i)\n",
    "\n",
    "    # Plot the images\n",
    "    for i in range(n_clusters_):\n",
    "        if len(indices[i]) < image_amount:\n",
    "            continue\n",
    "        plt.figure(figsize=(image_amount, 1))\n",
    "        #Add the title\n",
    "        plt.suptitle(f\"Cluster {i}\")\n",
    "        for j in range(image_amount):\n",
    "            plt.subplot(1, image_amount, j+1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(ski.io.imread(get_image_path(imageIDs[indices[i][np.random.randint(0, len(indices[i]))]])), cmap=\"gray\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prepped_images_from_folder(folders, verbose=False, conserve_memory=False):\n",
    "    for folder in folders:\n",
    "        if not os.path.isdir(f\"./{folder}\"):\n",
    "            raise ValueError(f\"Folder {folder} does not exist\")\n",
    "\n",
    "        if not os.path.isdir(f\"./{folder}\"):\n",
    "            os.mkdir(f\"./{folder}\")\n",
    "            if verbose:\n",
    "                print(f\"Created folder {folder}\")\n",
    "    images = ImageCollection([folder + \"/*.tiff\" for folder in folders], conserve_memory=conserve_memory)\n",
    "    if len(images) == 0:\n",
    "        raise ValueError(f\"No images found in folder {folders}\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "*And image loading*\n",
    "- [To the top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_prepped_images_from_folder(FOLDER_OF_PREPPED_IMAGES, \\\n",
    "                                        verbose=VERBOSE_FUNCTIONS, \\\n",
    "                                        conserve_memory=True)\n",
    "\n",
    "if VERBOSE:\n",
    "    print(f\"Number of images: {len(images)}\")\n",
    "    print(f\"Shape of images: {images[0].shape}\")\n",
    "    \n",
    "# Flatten the images\n",
    "images_1d_mapped = {}\n",
    "for index, image in enumerate(images):\n",
    "    name = images.files[index].split(\"/\")[-1].split(\".\")[0]\n",
    "    images_1d_mapped[name]=image.flatten()\n",
    "\n",
    "images_as_array = np.vstack(list(images_1d_mapped.values()))\n",
    "# Scale the data between 0 and 1\n",
    "images_as_array = images_as_array / 255\n",
    "\n",
    "\n",
    "pca = PCA(n_components= 25)\n",
    "pca.fit(images_as_array)\n",
    "images_as_pca = pca.transform(images_as_array)\n",
    "\n",
    "if VERBOSE:\n",
    "    print(f\"Shape of images_as_pca: {images_as_pca.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### DBSCAN\n",
    "\n",
    "- [To the top](#table-of-contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in np.arange(0.5, 10, 0.05):\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=4)\n",
    "    dbscan.fit(images_as_pca)\n",
    "\n",
    "    labels = dbscan.labels_\n",
    "    \n",
    "    outliers = 0\n",
    "\n",
    "    for index, label in enumerate(labels):\n",
    "        if label == -1:\n",
    "            if False:\n",
    "                print(f\"Outlier | Too much noise in the image{index}\")\n",
    "            outliers += 1\n",
    "\n",
    "    if VERBOSE:\n",
    "        if (len(set(labels)) - (1 if -1 in labels else 0)) >= 3: # Less than 4 gave garbage results\n",
    "            print(f\"Number of outliers: {outliers}\")\n",
    "            print(f\"Number of clusters: {len(set(labels)) - (1 if -1 in labels else 0)}\")\n",
    "            print((\"!!!!!!!!!!!!\", eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 2\n",
    "minPts = 2 * dimension \n",
    "radius = 4\n",
    "dbscan = DBSCAN(eps=radius, min_samples=minPts) \n",
    "dbscan.fit(images_as_pca)\n",
    "\n",
    "labels = dbscan.labels_\n",
    "print(\"number of clusters: \", len(set(labels)) - (1 if -1 in labels else 0))\n",
    "print(\"number of images: \", len(images_as_pca) - labels.tolist().count(-1))\n",
    "# Elements in each cluster \n",
    "# -1 is the noise\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "if VERBOSE:\n",
    "    print(dict(zip(unique, counts)))\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"Silhouette Coefficient: %0.3f\"\n",
    "        % silhouette_score(images_as_pca, labels))    # Is this correct? Shoulnd't it be images_as_pca?\n",
    "    print(\"Davis-Bouldin Index: %0.3f\"\n",
    "        % davies_bouldin_score(images_as_pca, labels))\n",
    "    print(\"Calinski-Harabasz Index: %0.3f\"\n",
    "        % calinski_harabasz_score(images_as_pca, labels))\n",
    "    \n",
    "plot_clusters(images_as_array, labels, len(set(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative clustering\n",
    "- [To the top](#table-of-contents) \n",
    "\n",
    "\n",
    "Do Hierarchical clustering, and see if we can find some clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do PCA\n",
    "pca = PCA(n_components=200)\n",
    "pca.fit(images_as_array)\n",
    "\n",
    "images_as_pca_for_agglomerative = pca.transform(images_as_array)\n",
    "\n",
    "if VERBOSE:\n",
    "    print(f\"Shape of images_as_pca: {images_as_pca.shape}\")\n",
    "\n",
    "# Create a AgglomerativeClustering object\n",
    "ms = AgglomerativeClustering(n_clusters=None, linkage=\"ward\", distance_threshold=100)\n",
    "\n",
    "# Train the model\n",
    "ms.fit(images_as_pca_for_agglomerative)\n",
    "\n",
    "# Extract cluster assignments for each data point.\n",
    "labels = ms.labels_\n",
    "\n",
    "# Coordinates of the cluster centers.\n",
    "#cluster_centers = ms.cluster_centers_\n",
    "\n",
    "# Count our clusters.\n",
    "n_clusters_ = len(np.unique(labels))\n",
    "if VERBOSE:\n",
    "    print(\"Number of estimated clusters:\", n_clusters_)\n",
    "\n",
    "#How many images are in each cluster?\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "if VERBOSE:\n",
    "    print(dict(zip(unique, counts)))\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"Silhouette Coefficient: %0.3f\"\n",
    "        % silhouette_score(images_as_array, labels))    # Is this correct? Shoulnd't it be images_as_pca?\n",
    "    print(\"Davis-Bouldin Index: %0.3f\"\n",
    "        % davies_bouldin_score(images_as_array, labels))\n",
    "    print(\"Calinski-Harabasz Index: %0.3f\"\n",
    "        % calinski_harabasz_score(images_as_array, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(images_as_array, labels, n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_real_clusters(list(images_1d_mapped.keys()), labels, n_clusters_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOM \n",
    "- [To the top](#table-of-contents)   \n",
    "\n",
    "\n",
    "This is good and all, but if we can use SOM (Self-organizing maps) we can get a 2D representation of the data with very high dimensionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do Self Organising Maps the images to extract features\n",
    "# Works well with PCA 25 components\n",
    "# Do SOM on the images\n",
    "array = images_as_pca\n",
    "som = MiniSom(int(10*np.sqrt(array.shape[0])), int(10*np.sqrt(array.shape[0])), array.shape[1], sigma=50, learning_rate=0.1, topology=\"rectangular\", random_seed=10)\n",
    "som.train(array, 1000)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pcolor(som.distance_map().T, cmap='bone_r')\n",
    "plt.colorbar()\n",
    "\n",
    "for i, x in enumerate(array):\n",
    "    w = som.winner(x)\n",
    "    plt.plot(w[0] + 0.5, w[1] + 0.5, 'o', markerfacecolor='None', markersize=1, markeredgecolor='r', markeredgewidth=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the images into the SOM space\n",
    "features = []\n",
    "for x in array:\n",
    "    w = som.winner(x)\n",
    "    features.append(w)\n",
    "features = np.array(features)\n",
    "\n",
    "# Cluster with Agglomerative Clustering\n",
    "ms = AgglomerativeClustering(n_clusters=None, linkage=\"average\", distance_threshold=100)\n",
    "\n",
    "# Train the model\n",
    "ms.fit(features)\n",
    "\n",
    "# Extract cluster assignments for each data point.\n",
    "labels = ms.labels_\n",
    "\n",
    "# Coordinates of the cluster centers.\n",
    "#cluster_centers = ms.cluster_centers_\n",
    "\n",
    "# Count our clusters.\n",
    "n_clusters_ = len(np.unique(labels))\n",
    "if VERBOSE:\n",
    "    print(\"Number of estimated clusters:\", n_clusters_)\n",
    "\n",
    "#How many images are in each cluster?\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "if VERBOSE:\n",
    "    print(dict(zip(unique, counts)))\n",
    "\n",
    "# Plot the clusters on a 2d plane\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(features[:,0], features[:,1], c=labels.astype(float))\n",
    "#Plot the labels\n",
    "for i, txt in enumerate(labels):\n",
    "    plt.annotate(txt, (features[i,0], features[i,1]))\n",
    "plt.show()\n",
    "\n",
    "#Metrics score for SOM implementation\n",
    "if VERBOSE:\n",
    "    print(\"Silhouette Coefficient: %0.3f\"\n",
    "        % silhouette_score(features, labels))\n",
    "    print(\"Davis-Bouldin Index: %0.3f\"\n",
    "        % davies_bouldin_score(features, labels))\n",
    "    print(\"Calinski-Harabasz Index: %0.3f\"\n",
    "        % calinski_harabasz_score(features, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(images_as_array, labels, n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_real_clusters(list(images_1d_mapped.keys()), labels, n_clusters_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing \n",
    "[To the top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# img = ski.io.imread(get_image_path(747207))\n",
    "# img = ski.io.imread(get_image_path(262909))\n",
    "# img = ski.io.imread(get_image_path(312941)) ##outlier, don't change\n",
    "# img = ski.io.imread(get_image_path(732356))\n",
    "# img = ski.io.imread(get_image_path(101151)) ##irregular\n",
    "# img = ski.io.imread(get_image_path(458590)) ## long\n",
    "# img = ski.io.imread(get_image_path(459014)) ##overlap\n",
    "# img = ski.io.imread(get_image_path(856044)) ##overlap\n",
    "# img = ski.io.imread(get_image_path(856535)) ##overlap\n",
    "# img = ski.io.imread(get_image_path(100295)) ##black stripe\n",
    "# img = ski.io.imread(get_image_path(856758)) ##black stripe\n",
    "# img = ski.io.imread(get_image_path(775905)) ##very inactive galaxy\n",
    "# img = ski.io.imread(get_image_path(744265)) ##very bright background\n",
    "# img = ski.io.imread(get_image_path(100008))\n"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "report_row_ids": [],
   "version": 3
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
